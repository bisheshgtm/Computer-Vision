{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2731ccdf",
   "metadata": {},
   "source": [
    "## Image Classification using Deep Multilayer Perceptron models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9adf56df",
   "metadata": {
    "id": "9adf56df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np \n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94619b80",
   "metadata": {},
   "source": [
    "**Deep multilayer perceptron (MLP) models with following specifications using TensorFlow for classifying the MNIST dataset. Training the model on the MNIST training set and evaluating its performance on the test set. Computing the mean of test accuracy for each of the following 4 Sequential models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794062ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8cbeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples : 60000 and each image is of shape (28, 28)\n",
      "Number of training examples : 10000 and each image is of shape (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d, %d)\"%(X_train.shape[1], X_train.shape[2]))\n",
    "print(\"Number of training examples :\", X_test.shape[0], \"and each image is of shape (%d, %d)\"%(X_test.shape[1], X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3085756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the (28*28) vector into single dimensional vector of 1 * 784 \n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]) \n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d84252b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples : 60000 and each image is of shape (784)\n",
      "Number of test examples : 10000 and each image is of shape (784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d)\"%(X_train.shape[1]))\n",
    "print(\"Number of test examples :\", X_test.shape[0], \"and each image is of shape (%d)\"%(X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "574b022b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa6943b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e4a70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "# X => (X - Xmin)/(Xmax-Xmin) = X/255\n",
    "X_train = X_train/255 \n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7ef8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77105f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 10\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "batch_size = 128 \n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31effba",
   "metadata": {},
   "source": [
    "**Model-1: 4 hidden layers having 128, 64, 32, 16 number of neurons respectively with activation function sigmoid, tanh, relu and selu respectively and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as SGD with batch size set to 32.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16a25013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='sigmoid', input_shape=(input_dim,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='tanh'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(16, activation='selu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.SGD(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=5,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', score[1])\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb03e6ce",
   "metadata": {},
   "source": [
    "**Model-2: 4 hidden layers having 128, 64, 32, 16 number of neurons respectively with activation function sigmoid, tanh, relu and selu respectively and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as Adam with batch size set to 32.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a11da041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='sigmoid', input_shape=(input_dim,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='tanh'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(16, activation='selu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=5,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', score[1])\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8238f2ba",
   "metadata": {},
   "source": [
    "**Model-3: 4 hidden layers having 128, 64, 32, 16 number of neurons respectively with activation function sigmoid, tanh, relu and selu respectively and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as AdamW with learning rate 0.1 with batch size set to 32.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12533dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model3():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='sigmoid', input_shape=(input_dim,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='tanh'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(16, activation='selu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.AdamW(learning_rate=0.1),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=5,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', score[1])\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992cd0db",
   "metadata": {},
   "source": [
    "**Model-4: 4 hidden layers having 128, 64, 32, 16 number of neurons respectively with activation function sigmoid, tanh, relu and selu respectively and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as Nadam with learning rate 0.1 with batch size set to 32.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb5c4ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model4():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='sigmoid', input_shape=(input_dim,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='tanh'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(16, activation='selu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Nadam(learning_rate=0.1),metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=5,verbose=1,validation_data=(X_test, y_test))\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', score[1])\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f33d2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2963 - accuracy: 0.1343 - val_loss: 2.0702 - val_accuracy: 0.4041\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.7748 - accuracy: 0.3533 - val_loss: 1.0025 - val_accuracy: 0.6825\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2647 - accuracy: 0.5436 - val_loss: 0.7398 - val_accuracy: 0.7870\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0335 - accuracy: 0.6407 - val_loss: 0.6048 - val_accuracy: 0.8272\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9170 - accuracy: 0.6916 - val_loss: 0.5346 - val_accuracy: 0.8479\n",
      "Test accuracy: 0.8478999733924866\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2537 - accuracy: 0.1610 - val_loss: 1.7519 - val_accuracy: 0.5139\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6486 - accuracy: 0.3943 - val_loss: 0.9613 - val_accuracy: 0.6987\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2309 - accuracy: 0.5599 - val_loss: 0.7640 - val_accuracy: 0.7606\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0380 - accuracy: 0.6395 - val_loss: 0.6383 - val_accuracy: 0.8132\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9145 - accuracy: 0.6965 - val_loss: 0.5608 - val_accuracy: 0.8417\n",
      "Test accuracy: 0.84170001745224\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2789 - accuracy: 0.1452 - val_loss: 1.8965 - val_accuracy: 0.4085\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.7744 - accuracy: 0.3341 - val_loss: 1.1912 - val_accuracy: 0.6084\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3746 - accuracy: 0.4897 - val_loss: 0.8549 - val_accuracy: 0.7356\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1186 - accuracy: 0.6002 - val_loss: 0.6849 - val_accuracy: 0.8031\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9748 - accuracy: 0.6639 - val_loss: 0.5993 - val_accuracy: 0.8265\n",
      "Test accuracy: 0.8264999985694885\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.2129 - accuracy: 0.1717 - val_loss: 1.5957 - val_accuracy: 0.5180\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6083 - accuracy: 0.4026 - val_loss: 0.9803 - val_accuracy: 0.6804\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2226 - accuracy: 0.5590 - val_loss: 0.7484 - val_accuracy: 0.7738\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0222 - accuracy: 0.6453 - val_loss: 0.6248 - val_accuracy: 0.8143\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9010 - accuracy: 0.6971 - val_loss: 0.5390 - val_accuracy: 0.8486\n",
      "Test accuracy: 0.8485999703407288\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.2871 - accuracy: 0.1444 - val_loss: 1.9692 - val_accuracy: 0.3762\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.7380 - accuracy: 0.3602 - val_loss: 1.0348 - val_accuracy: 0.6445\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2615 - accuracy: 0.5422 - val_loss: 0.7544 - val_accuracy: 0.7738\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0370 - accuracy: 0.6415 - val_loss: 0.5992 - val_accuracy: 0.8254\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8970 - accuracy: 0.6979 - val_loss: 0.5159 - val_accuracy: 0.8484\n",
      "Test accuracy: 0.8483999967575073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8426199913024902"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1=np.zeros(5)\n",
    "for i in range(5):\n",
    "    res1[i]=model1()\n",
    "np.mean(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a69d6fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.9042 - accuracy: 0.7014 - val_loss: 0.2909 - val_accuracy: 0.9171\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4434 - accuracy: 0.8744 - val_loss: 0.2102 - val_accuracy: 0.9409\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3547 - accuracy: 0.9027 - val_loss: 0.1818 - val_accuracy: 0.9484\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3048 - accuracy: 0.9167 - val_loss: 0.1726 - val_accuracy: 0.9546\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2805 - accuracy: 0.9245 - val_loss: 0.1503 - val_accuracy: 0.9596\n",
      "Test accuracy: 0.9595999717712402\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.9201 - accuracy: 0.6944 - val_loss: 0.2824 - val_accuracy: 0.9222\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4351 - accuracy: 0.8789 - val_loss: 0.2087 - val_accuracy: 0.9396\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3462 - accuracy: 0.9059 - val_loss: 0.1790 - val_accuracy: 0.9492\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3070 - accuracy: 0.9169 - val_loss: 0.1577 - val_accuracy: 0.9574\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2771 - accuracy: 0.9246 - val_loss: 0.1506 - val_accuracy: 0.9601\n",
      "Test accuracy: 0.960099995136261\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.8900 - accuracy: 0.7041 - val_loss: 0.2772 - val_accuracy: 0.9184\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4359 - accuracy: 0.8774 - val_loss: 0.2087 - val_accuracy: 0.9390\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3471 - accuracy: 0.9053 - val_loss: 0.1897 - val_accuracy: 0.9458\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3091 - accuracy: 0.9156 - val_loss: 0.1629 - val_accuracy: 0.9537\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2796 - accuracy: 0.9245 - val_loss: 0.1474 - val_accuracy: 0.9597\n",
      "Test accuracy: 0.9596999883651733\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.9014 - accuracy: 0.6998 - val_loss: 0.2836 - val_accuracy: 0.9196\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4342 - accuracy: 0.8765 - val_loss: 0.2114 - val_accuracy: 0.9403\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3508 - accuracy: 0.9037 - val_loss: 0.1774 - val_accuracy: 0.9511\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3055 - accuracy: 0.9179 - val_loss: 0.1593 - val_accuracy: 0.9562\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2777 - accuracy: 0.9242 - val_loss: 0.1489 - val_accuracy: 0.9600\n",
      "Test accuracy: 0.9599999785423279\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.8974 - accuracy: 0.7049 - val_loss: 0.2872 - val_accuracy: 0.9207\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4333 - accuracy: 0.8765 - val_loss: 0.2149 - val_accuracy: 0.9393\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3573 - accuracy: 0.9019 - val_loss: 0.1877 - val_accuracy: 0.9476\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3116 - accuracy: 0.9156 - val_loss: 0.1658 - val_accuracy: 0.9564\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2823 - accuracy: 0.9236 - val_loss: 0.1524 - val_accuracy: 0.9585\n",
      "Test accuracy: 0.9585000276565552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9595799922943116"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2=np.zeros(5)\n",
    "for i in range(5):\n",
    "    res2[i]=model2()\n",
    "np.mean(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83925d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3375 - accuracy: 0.0992 - val_loss: 2.3369 - val_accuracy: 0.1010\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3394 - accuracy: 0.1018 - val_loss: 2.3494 - val_accuracy: 0.1032\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.4042 - accuracy: 0.1008 - val_loss: 2.3120 - val_accuracy: 0.1032\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3244 - accuracy: 0.1029 - val_loss: 2.3101 - val_accuracy: 0.0892\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3333 - accuracy: 0.1015 - val_loss: 2.3456 - val_accuracy: 0.0982\n",
      "Test accuracy: 0.0982000008225441\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3386 - accuracy: 0.1011 - val_loss: 2.3352 - val_accuracy: 0.1028\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3380 - accuracy: 0.1039 - val_loss: 2.3409 - val_accuracy: 0.1010\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3609 - accuracy: 0.1016 - val_loss: 2.3239 - val_accuracy: 0.0958\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3268 - accuracy: 0.1015 - val_loss: 2.3146 - val_accuracy: 0.0982\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3376 - accuracy: 0.1030 - val_loss: 2.3364 - val_accuracy: 0.1028\n",
      "Test accuracy: 0.10279999673366547\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3380 - accuracy: 0.1046 - val_loss: 2.3267 - val_accuracy: 0.0974\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3378 - accuracy: 0.1011 - val_loss: 2.3208 - val_accuracy: 0.1010\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3376 - accuracy: 0.1013 - val_loss: 2.3783 - val_accuracy: 0.1032\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3369 - accuracy: 0.1019 - val_loss: 2.3447 - val_accuracy: 0.0958\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.4312 - accuracy: 0.1009 - val_loss: 2.3104 - val_accuracy: 0.1135\n",
      "Test accuracy: 0.11349999904632568\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3394 - accuracy: 0.1018 - val_loss: 2.3285 - val_accuracy: 0.1028\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3388 - accuracy: 0.1008 - val_loss: 2.3128 - val_accuracy: 0.1010\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3374 - accuracy: 0.1025 - val_loss: 2.3118 - val_accuracy: 0.1135\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.8945 - accuracy: 0.0994 - val_loss: 2.6408 - val_accuracy: 0.1010\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.6109 - accuracy: 0.0987 - val_loss: 2.6576 - val_accuracy: 0.0982\n",
      "Test accuracy: 0.0982000008225441\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 2.3385 - accuracy: 0.1023 - val_loss: 2.3500 - val_accuracy: 0.1135\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3369 - accuracy: 0.1031 - val_loss: 2.3763 - val_accuracy: 0.0958\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3402 - accuracy: 0.1023 - val_loss: 2.3361 - val_accuracy: 0.1032\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3415 - accuracy: 0.1020 - val_loss: 2.3184 - val_accuracy: 0.1135\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.4346 - accuracy: 0.1022 - val_loss: 2.3063 - val_accuracy: 0.1135\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.105239999294281"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3=np.zeros(5)\n",
    "for i in range(5):\n",
    "    res3[i]=model3()\n",
    "np.mean(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e12020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 2.3287 - accuracy: 0.1034 - val_loss: 2.3359 - val_accuracy: 0.1010\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3478 - accuracy: 0.1020 - val_loss: 2.3350 - val_accuracy: 0.1009\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3268 - accuracy: 0.1010 - val_loss: 2.3188 - val_accuracy: 0.0980\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3255 - accuracy: 0.1010 - val_loss: 2.3158 - val_accuracy: 0.0980\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3270 - accuracy: 0.1013 - val_loss: 2.3211 - val_accuracy: 0.0980\n",
      "Test accuracy: 0.09799999743700027\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 2.3609 - accuracy: 0.1030 - val_loss: 2.3114 - val_accuracy: 0.1135\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3307 - accuracy: 0.1023 - val_loss: 2.3092 - val_accuracy: 0.1032\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3218 - accuracy: 0.1024 - val_loss: 2.3211 - val_accuracy: 0.1028\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.4662 - accuracy: 0.1006 - val_loss: 2.4032 - val_accuracy: 0.1135\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3420 - accuracy: 0.1033 - val_loss: 2.3236 - val_accuracy: 0.0958\n",
      "Test accuracy: 0.0957999974489212\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 2.3269 - accuracy: 0.1047 - val_loss: 2.3276 - val_accuracy: 0.1028\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3271 - accuracy: 0.1028 - val_loss: 2.3263 - val_accuracy: 0.1032\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3279 - accuracy: 0.1015 - val_loss: 2.3213 - val_accuracy: 0.1010\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3274 - accuracy: 0.1013 - val_loss: 2.3294 - val_accuracy: 0.1010\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3278 - accuracy: 0.1033 - val_loss: 2.3150 - val_accuracy: 0.1010\n",
      "Test accuracy: 0.10100000351667404\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 10s 4ms/step - loss: 2.3345 - accuracy: 0.1047 - val_loss: 2.3079 - val_accuracy: 0.0982\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3226 - accuracy: 0.1030 - val_loss: 2.3240 - val_accuracy: 0.1028\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3279 - accuracy: 0.1014 - val_loss: 2.3118 - val_accuracy: 0.1135\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3269 - accuracy: 0.1022 - val_loss: 2.3284 - val_accuracy: 0.0892\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.3270 - accuracy: 0.1032 - val_loss: 2.3165 - val_accuracy: 0.1028\n",
      "Test accuracy: 0.10279999673366547\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 2.3279 - accuracy: 0.0999 - val_loss: 2.3233 - val_accuracy: 0.1009\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3279 - accuracy: 0.1012 - val_loss: 2.3599 - val_accuracy: 0.1028\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3275 - accuracy: 0.1027 - val_loss: 2.3164 - val_accuracy: 0.1135\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3292 - accuracy: 0.1026 - val_loss: 2.3332 - val_accuracy: 0.1028\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3276 - accuracy: 0.1013 - val_loss: 2.3139 - val_accuracy: 0.1135\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10221999883651733"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res4=np.zeros(5)\n",
    "for i in range(5):\n",
    "    res4[i]=model4()\n",
    "np.mean(res4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b355a1",
   "metadata": {},
   "source": [
    "**Tuning the hyperparameters using kerastuner to select the best learning rate among the set {0.1, 0.01, 0.15} with batch size varying between {4,8,16} and first hidden layer neurons varying between 250 to 260 with a step value of 2. 2nd, 3rd and 4th hidden layer contains 16, 8, 4 numbers of neurons respectively. The four layers have activation function sigmoid, tanh, relu and selu respectively. Using optimizer as SGD and finding the best hyperparameters to predict the MNIST test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a7b34ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Define the first hidden layer with tunable number of neurons\n",
    "    hp_neurons = hp.Int('neurons', min_value=250, max_value=260, step=2)\n",
    "    model.add(layers.Dense(units=hp_neurons, activation='sigmoid', input_shape=(784,)))\n",
    "\n",
    "    # Define the second, third, and fourth hidden layers\n",
    "    model.add(layers.Dense(16, activation='tanh'))\n",
    "    model.add(layers.Dense(8, activation='relu'))\n",
    "    model.add(layers.Dense(4, activation='selu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    # Tune the learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01, 0.15])\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=hp_learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a17bc278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from keras_tuner_mnist\\mnist_hyperparameter_tuning\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='keras_tuner_mnist',\n",
    "    project_name='mnist_hyperparameter_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2dfd738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 35s]\n",
      "val_accuracy: 0.874749998251597\n",
      "\n",
      "Best val_accuracy So Far: 0.9420555432637533\n",
      "Total elapsed time: 00h 06m 36s\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9df5bc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.1\n",
      "Best number of neurons: 252\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"Best number of neurons: {best_hps.get('neurons')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "223b9c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 1ms/step - loss: 0.9152 - accuracy: 0.6926 - val_loss: 0.4512 - val_accuracy: 0.8698\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4119 - accuracy: 0.8853 - val_loss: 0.3003 - val_accuracy: 0.9193\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2940 - accuracy: 0.9181 - val_loss: 0.2613 - val_accuracy: 0.9298\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2257 - accuracy: 0.9367 - val_loss: 0.1866 - val_accuracy: 0.9500\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1857 - accuracy: 0.9483 - val_loss: 0.2160 - val_accuracy: 0.9412\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1582 - accuracy: 0.9551 - val_loss: 0.2240 - val_accuracy: 0.9344\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1370 - accuracy: 0.9613 - val_loss: 0.1481 - val_accuracy: 0.9609\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1206 - accuracy: 0.9660 - val_loss: 0.1498 - val_accuracy: 0.9607\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1067 - accuracy: 0.9693 - val_loss: 0.1552 - val_accuracy: 0.9576\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0961 - accuracy: 0.9733 - val_loss: 0.1422 - val_accuracy: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21228dafb50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8df65109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 864us/step - loss: 0.1442 - accuracy: 0.9626\n",
      "Test accuracy: 0.9625999927520752\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae837c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
