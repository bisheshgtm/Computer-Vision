{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f65ac8",
   "metadata": {},
   "source": [
    "# Image Classification using CNN \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30c22c7",
   "metadata": {},
   "source": [
    "**Implementing convolutional neural network (CNN) models with following specifications using TensorFlow for classifying the MNIST dataset. Training the model on the MNIST training set and evaluating its performance on the test set. Calling the modularised code 3 times and computing the mean of test accuracy for each of the following 3 Sequential models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5249ef63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils,layers,models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np \n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45c01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eecf84",
   "metadata": {},
   "source": [
    "**Model-1: Add a convolution layer with 32 3 × 3 filters with stride 2 and relu activation. Add a maxpooling layer with kernel size 2 × 2 with stride 1. Add a convolution layer with 16 4 × 4 filters with stride 2 and relu activation. Add a maxpooling layer with kernel size 4 × 4 with stride 2. Flatten the output and add a fully connected layer with 8 neurons with relu activation. Add a fully connected layer with 10 neurons and softmax activation. Use Adam optimizer with batch size 128, learning rate 0.01 and epochs set to 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2cdca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_1():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), strides=(2, 2), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2), strides=(1, 1)),\n",
    "        layers.Conv2D(16, (4, 4), strides=(2, 2), activation='relu'),\n",
    "        layers.MaxPooling2D((4, 4), strides=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19611c20",
   "metadata": {},
   "source": [
    "**Model-2: Add a convolution layer with 32 3 × 3 filters with stride 2 and relu activation. Add an average pooling layer with kernel size 2 × 2 with stride 1. Add a convolution layer with 16 4 × 4 filters with stride 2 and relu activation. Add an average pooling layer with kernel size 4 × 4 with stride 2. Flatten the output and add a fully connected layer with 8 neurons with relu activation. Add a fully connected layer with 10 neurons and softmax activation. Use Adam optimizer with batch size 128, learning rate 0.01 and epochs set to 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92fc0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_2():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), strides=(2, 2), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.AveragePooling2D((2, 2), strides=(1, 1)),\n",
    "        layers.Conv2D(16, (4, 4), strides=(2, 2), activation='relu'),\n",
    "        layers.AveragePooling2D((4, 4), strides=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489bc3bb",
   "metadata": {},
   "source": [
    "**Model-3: Add a convolution layer with 32 3 × 3 filters with stride 2, relu activation and same value padding. Add a maxpooling layer with kernel size 2 × 2 with stride 1. Add a convolution layer with 16 4 × 4 filters with stride 2 and relu activation. Add a maxpooling layer with kernel size 4 × 4 with stride 2. Flatten the output and add a fully connected layer with 8 neurons with relu activation. Add a fully connected layer with 10 neurons and softmax activation. Use Adam optimizer with batch size 128, learning rate 0.01 and epochs set to 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b2fd13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_3():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2), strides=(1, 1)),\n",
    "        layers.Conv2D(16, (4, 4), strides=(2, 2), activation='relu'),\n",
    "        layers.MaxPooling2D((4, 4), strides=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a31a2a8",
   "metadata": {},
   "source": [
    "**Model-4: Add a convolution layer with 32 3 × 3 filters with stride 2, relu activation and zero padding. Add a maxpooling layer with kernel size 2 × 2 with stride 1. Add a convolution layer with 16 4 × 4 filters with stride 2 and relu activation and zero padding. Add a maxpooling layer with kernel size 4 × 4 with stride 2. Flatten the output and add a fully connected layer with 8 neurons with relu activation. Add a fully connected layer with 10 neurons and softmax activation. Use Adam optimizer with batch size 128, learning rate 0.01 and epochs set to 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfc0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_4():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2), strides=(1, 1)),\n",
    "        layers.Conv2D(16, (4, 4), strides=(2, 2), activation='relu',padding='same'),\n",
    "        layers.MaxPooling2D((4, 4), strides=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a617274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=2)\n",
    "    _, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53dcd162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 - 3s - loss: 0.8936 - accuracy: 0.6829 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 2s - loss: 0.4308 - accuracy: 0.8641 - 2s/epoch - 5ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 2s - loss: 0.3583 - accuracy: 0.8876 - 2s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 2s - loss: 0.3083 - accuracy: 0.9036 - 2s/epoch - 5ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 2s - loss: 0.2881 - accuracy: 0.9105 - 2s/epoch - 5ms/step\n",
      "313/313 - 1s - loss: 0.3025 - accuracy: 0.9062 - 788ms/epoch - 3ms/step\n",
      "test accuracy for model 1 run 0: 0.9061999917030334\n",
      "Epoch 1/5\n",
      "469/469 - 3s - loss: 1.1429 - accuracy: 0.5856 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 3s - loss: 0.6029 - accuracy: 0.7999 - 3s/epoch - 5ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 2s - loss: 0.5399 - accuracy: 0.8226 - 2s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 2s - loss: 0.4803 - accuracy: 0.8455 - 2s/epoch - 5ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 2s - loss: 0.4475 - accuracy: 0.8579 - 2s/epoch - 5ms/step\n",
      "313/313 - 1s - loss: 0.4189 - accuracy: 0.8667 - 786ms/epoch - 3ms/step\n",
      "test accuracy for model 1 run 1: 0.8666999936103821\n",
      "Epoch 1/5\n",
      "469/469 - 3s - loss: 2.3020 - accuracy: 0.1106 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 3s - loss: 2.3020 - accuracy: 0.1117 - 3s/epoch - 5ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 2s - loss: 2.3017 - accuracy: 0.1115 - 2s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 2s - loss: 2.3019 - accuracy: 0.1120 - 2s/epoch - 5ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 2s - loss: 2.3018 - accuracy: 0.1113 - 2s/epoch - 5ms/step\n",
      "313/313 - 1s - loss: 2.3021 - accuracy: 0.1135 - 788ms/epoch - 3ms/step\n",
      "test accuracy for model 1 run 2: 0.11349999904632568\n",
      "Mean Test Accuracy for Model 1: 0.6287999947865804\n"
     ]
    }
   ],
   "source": [
    "num_runs = 3\n",
    "test_accuracies = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    model_1 = create_model_1()\n",
    "    test_accuracy = train_and_evaluate_model(model_1, X_train, y_train, X_test, y_test)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print(f\"test accuracy for model 1 run {_}:\", test_accuracy)\n",
    "\n",
    "mean_test_accuracy_model_1 = np.mean(test_accuracies)\n",
    "print(\"Mean Test Accuracy for Model 1:\", mean_test_accuracy_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8b39ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 - 3s - loss: 1.4892 - accuracy: 0.4514 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 3s - loss: 0.8779 - accuracy: 0.6892 - 3s/epoch - 6ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 3s - loss: 0.7118 - accuracy: 0.7567 - 3s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 3s - loss: 0.6370 - accuracy: 0.7838 - 3s/epoch - 6ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 3s - loss: 0.5811 - accuracy: 0.8071 - 3s/epoch - 5ms/step\n",
      "313/313 - 1s - loss: 0.5203 - accuracy: 0.8312 - 778ms/epoch - 2ms/step\n",
      "test accuracy for model 2 run 0: 0.8312000036239624\n",
      "Epoch 1/5\n",
      "469/469 - 3s - loss: 1.3583 - accuracy: 0.4972 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 3s - loss: 0.8066 - accuracy: 0.7222 - 3s/epoch - 6ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 3s - loss: 0.6361 - accuracy: 0.7916 - 3s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 3s - loss: 0.4391 - accuracy: 0.8666 - 3s/epoch - 6ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 3s - loss: 0.3738 - accuracy: 0.8877 - 3s/epoch - 6ms/step\n",
      "313/313 - 1s - loss: 0.3782 - accuracy: 0.8853 - 792ms/epoch - 3ms/step\n",
      "test accuracy for model 2 run 1: 0.8852999806404114\n",
      "Epoch 1/5\n",
      "469/469 - 3s - loss: 1.4987 - accuracy: 0.4326 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 3s - loss: 0.8424 - accuracy: 0.7125 - 3s/epoch - 5ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 3s - loss: 0.6318 - accuracy: 0.7968 - 3s/epoch - 6ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 3s - loss: 0.5277 - accuracy: 0.8349 - 3s/epoch - 5ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 3s - loss: 0.4786 - accuracy: 0.8508 - 3s/epoch - 6ms/step\n",
      "313/313 - 1s - loss: 0.4430 - accuracy: 0.8659 - 827ms/epoch - 3ms/step\n",
      "test accuracy for model 2 run 2: 0.8658999800682068\n",
      "Mean Test Accuracy for Model 2: 0.8607999881108602\n"
     ]
    }
   ],
   "source": [
    "test_accuracies_model2 = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    model_2 = create_model_2()\n",
    "    test_accuracy = train_and_evaluate_model(model_2, X_train, y_train, X_test, y_test)\n",
    "    test_accuracies_model2.append(test_accuracy)\n",
    "    print(f\"test accuracy for model 2 run {_}:\", test_accuracy)\n",
    "\n",
    "mean_test_accuracy_model_2 = np.mean(test_accuracies_model2)\n",
    "print(\"Mean Test Accuracy for Model 2:\", mean_test_accuracy_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "524ea1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 - 3s - loss: 0.5857 - accuracy: 0.8040 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 3s - loss: 0.2478 - accuracy: 0.9232 - 3s/epoch - 6ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 2s - loss: 0.2007 - accuracy: 0.9387 - 2s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 2s - loss: 0.1766 - accuracy: 0.9455 - 2s/epoch - 5ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 2s - loss: 0.1572 - accuracy: 0.9505 - 2s/epoch - 5ms/step\n",
      "313/313 - 1s - loss: 0.1844 - accuracy: 0.9452 - 1s/epoch - 4ms/step\n",
      "test accuracy for model 3 run 0: 0.9452000260353088\n",
      "Epoch 1/5\n",
      "469/469 - 3s - loss: 1.7705 - accuracy: 0.2731 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 3s - loss: 1.5250 - accuracy: 0.3488 - 3s/epoch - 5ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 2s - loss: 1.4467 - accuracy: 0.3683 - 2s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 3s - loss: 0.9657 - accuracy: 0.6407 - 3s/epoch - 5ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 3s - loss: 0.7106 - accuracy: 0.7593 - 3s/epoch - 6ms/step\n",
      "313/313 - 1s - loss: 0.6566 - accuracy: 0.7907 - 845ms/epoch - 3ms/step\n",
      "test accuracy for model 3 run 1: 0.7907000184059143\n",
      "Epoch 1/5\n",
      "469/469 - 3s - loss: 0.9621 - accuracy: 0.6727 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 2s - loss: 0.5406 - accuracy: 0.8271 - 2s/epoch - 5ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 2s - loss: 0.4592 - accuracy: 0.8555 - 2s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 2s - loss: 0.4202 - accuracy: 0.8669 - 2s/epoch - 5ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 2s - loss: 0.4012 - accuracy: 0.8762 - 2s/epoch - 5ms/step\n",
      "313/313 - 1s - loss: 0.3897 - accuracy: 0.8750 - 798ms/epoch - 3ms/step\n",
      "test accuracy for model 3 run 2: 0.875\n",
      "Mean Test Accuracy for Model 3: 0.8703000148137411\n"
     ]
    }
   ],
   "source": [
    "test_accuracies_model3 = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    model_3 = create_model_3()\n",
    "    test_accuracy = train_and_evaluate_model(model_3, X_train, y_train, X_test, y_test)\n",
    "    test_accuracies_model3.append(test_accuracy)\n",
    "    print(f\"test accuracy for model 3 run {_}:\", test_accuracy)\n",
    "\n",
    "mean_test_accuracy_model_3 = np.mean(test_accuracies_model3)\n",
    "print(\"Mean Test Accuracy for Model 3:\", mean_test_accuracy_model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c96fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 - 3s - loss: 0.6403 - accuracy: 0.7867 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 3s - loss: 0.2893 - accuracy: 0.9120 - 3s/epoch - 6ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 3s - loss: 0.2323 - accuracy: 0.9294 - 3s/epoch - 5ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 3s - loss: 0.2067 - accuracy: 0.9363 - 3s/epoch - 6ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 3s - loss: 0.1895 - accuracy: 0.9413 - 3s/epoch - 6ms/step\n",
      "313/313 - 1s - loss: 0.1854 - accuracy: 0.9450 - 816ms/epoch - 3ms/step\n",
      "test accuracy for model 4 run 0: 0.9449999928474426\n",
      "Epoch 1/5\n",
      "469/469 - 3s - loss: 0.7962 - accuracy: 0.7244 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 3s - loss: 0.3387 - accuracy: 0.8950 - 3s/epoch - 6ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 3s - loss: 0.2687 - accuracy: 0.9184 - 3s/epoch - 6ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 3s - loss: 0.2340 - accuracy: 0.9289 - 3s/epoch - 5ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 3s - loss: 0.2194 - accuracy: 0.9332 - 3s/epoch - 6ms/step\n",
      "313/313 - 1s - loss: 0.2218 - accuracy: 0.9323 - 854ms/epoch - 3ms/step\n",
      "test accuracy for model 4 run 1: 0.9322999715805054\n",
      "Epoch 1/5\n",
      "469/469 - 3s - loss: 0.5927 - accuracy: 0.8007 - 3s/epoch - 7ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 3s - loss: 0.2174 - accuracy: 0.9339 - 3s/epoch - 6ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 3s - loss: 0.1738 - accuracy: 0.9473 - 3s/epoch - 6ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 3s - loss: 0.1509 - accuracy: 0.9548 - 3s/epoch - 6ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 3s - loss: 0.1393 - accuracy: 0.9577 - 3s/epoch - 6ms/step\n",
      "313/313 - 1s - loss: 0.1345 - accuracy: 0.9584 - 806ms/epoch - 3ms/step\n",
      "test accuracy for model 4 run 2: 0.9584000110626221\n",
      "Mean Test Accuracy for Model 4: 0.9452333251635233\n"
     ]
    }
   ],
   "source": [
    "test_accuracies_model4 = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    model_4 = create_model_4()\n",
    "    test_accuracy = train_and_evaluate_model(model_4, X_train, y_train, X_test, y_test)\n",
    "    test_accuracies_model4.append(test_accuracy)\n",
    "    print(f\"test accuracy for model 4 run {_}:\", test_accuracy)\n",
    "\n",
    "mean_test_accuracy_model_4 = np.mean(test_accuracies_model4)\n",
    "print(\"Mean Test Accuracy for Model 4:\", mean_test_accuracy_model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6759ecea",
   "metadata": {},
   "source": [
    "**Using kerastuner to select the best hyperparameters after observing above models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d82518ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Define hyperparameters\n",
    "    filters = hp.Int('filters', min_value=32, max_value=128, step=32)\n",
    "    kernel_size = hp.Choice('kernel_size', values=[3, 5])\n",
    "    dense_units = hp.Int('dense_units', min_value=64, max_value=256, step=64)\n",
    "    pooling_type = hp.Choice('pooling_type', values=['max', 'avg'])\n",
    "    activation_func = hp.Choice('activation_func', values=['relu', 'tanh', 'sigmoid'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(layers.Conv2D(filters, kernel_size, activation=activation_func, input_shape=(28, 28, 1)))\n",
    "    \n",
    "    if pooling_type == 'max':\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    else:\n",
    "        model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(filters*2, kernel_size, activation=activation_func))\n",
    "    \n",
    "    if pooling_type == 'max':\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    else:\n",
    "        model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(dense_units, activation=activation_func))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "278a133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='mnist_learning_rate_tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7d9a436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 04m 50s]\n",
      "val_accuracy: 0.9922000169754028\n",
      "\n",
      "Best val_accuracy So Far: 0.9922000169754028\n",
      "Total elapsed time: 00h 18m 13s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=3,\n",
    "             validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e66b4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2244e410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "filters: 128\n",
      "kernel_size: 5\n",
      "dense_units: 128\n",
      "pooling_type: max\n",
      "activation_func: relu\n",
      "learning_rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters:\")\n",
    "for hyperparameter, value in best_hps.values.items():\n",
    "    print(f\"{hyperparameter}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a8d837c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0933 - accuracy: 0.9709 - val_loss: 0.0317 - val_accuracy: 0.9893\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 96s 51ms/step - loss: 0.0333 - accuracy: 0.9900 - val_loss: 0.0336 - val_accuracy: 0.9887\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 96s 51ms/step - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.0268 - val_accuracy: 0.9904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fc1571a910>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=3, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4867f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
